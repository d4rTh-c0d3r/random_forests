Results of Classification Random Forests on NIST data.

1. As Function of Forest Size [max_depth = 10; min_elements = 10; randomness = 20]

1  0.64
2  0.53
3  0.72
4  0.73
5  0.72
6  0.74
7  0.85
8  0.83
9  0.84
10 0.82
11 0.78
12 0.75
13 0.82
14 0.80
15 0.82
16 0.80
17 0.82
18 0.85
19 0.89
20 0.82
21 0.80
22 0.80
23 0.83
24 0.84
25 0.81
26 0.82
27 0.85
28 0.85
29 0.84
30 0.81


2. As Function of Forest Size [max_depth = 2; min_elements = 10; randomness = 20]

1  0.17
2  0.27
3  0.46
4  0.31
5  0.46
6  0.39
7  0.42
8  0.40
9  0.40
10 0.39
11 0.48
12 0.45
13 0.44
14 0.63
15 0.41
16 0.49
17 0.56
18 0.42
19 0.59
20 0.50
21 0.42
22 0.61
23 0.39
24 0.45
25 0.37
26 0.63
27 0.45
28 0.49
29 0.51
30 0.48

3. As Function of Max Depth [forest_size = 30; min_elements = 10; randomness = 20]

1  0.22 [UNDER FITTING]
2  0.47
3  0.79
4  0.78
5  0.84
6  0.83
7  0.78
8  0.80
9  0.84
10 0.88 [MAXIMA AROUND HERE]
11 0.86
12 0.86
13 0.77
14 0.83
15 0.82 [OVER FITTING]

4. As Function of Max Depth [forest_size = 2; min_elements = 10; randomness = 20]

1  0.15 [UNDER FITTING]
2  0.33
3  0.43
4  0.52
5  0.50
6  0.67
7  0.57
8  0.64
9  0.56
10 0.53
11 0.66
12 0.64
13 0.54
14 0.65
15 0.56
16 0.58
17 0.67

5. For data with 2 squares (inner and outer), the accuracy was ~90%.
   When compared to SVM on data with two types of points, I got almost similar results for linear separation.
   For non linear separation, SVM didn't perform well, which was mainly because I'm using a linear kernel.
   (Learn how to choose Kernels)

Results of Regression Random Forests on Linear Data [-5 < x < 0 : x+5 ; 0 < x < 5 : 5-x]. (Not Noisy)

6. As Function of Forest Size [max_depth = 10; min_elements = 5; randomness = 20]

1  0.001624999999999997
2  0.003907972910132831
3  0.008814331291120027
4  0.016903994763226744
5  0.003660161239860374
6  0.007376177828496803
7  0.008442639388563192
8  0.022192914216190674
9  0.000580617289348175
10 0.009356206450177424
11 0.005665753666320715
12 0.012051569664405366
13 0.004775057453180761
14 0.002571538051530807
15 0.009073388065638803
16 0.003640947057241152
17 0.005050593402472834
18 0.004397059067656960
19 0.004038796193462257
20 0.004355277464112487
21 0.003991595669051132
22 0.008295131687590298
23 0.008264739033304064
24 0.004252622709070316
25 0.009530774215443193
26 0.014667464215323469
27 0.006804610068463694
28 0.003808388878371289
29 0.004123057980812707
30 0.006145764699429973

7. As Function of Forest Size [max_depth = 2; min_elements = 5; randomness = 20]

1  1.4628680698503942
2  0.3137045901772543
3  0.2139603539319781
4  0.7354043242007264
5  0.3136887886709200
6  0.4388414171241394
7  0.4002552572241111
8  0.2693691048956234
9  0.3349346925758908
10 0.2569382126626372
11 0.6593302590730014
12 0.2614676241543204
13 0.5529784412170293
14 0.11150802953457302
15 0.5095926682256813
16 0.3483159435674095
17 0.11869536493428853
18 0.17560584570516483
19 0.2574312511659087
20 0.47177796791761706
21 0.36503327085912346
22 0.505334022629274
23 0.41819772498645297
24 0.1928470623998046
25 0.32722133337388126
26 0.20217356348539378
27 0.5665737464695869
28 0.22557412955932285
29 0.44236871591625765
30 0.19730318116679593

8. As Function of max_depth [forest_size = 10; min_elements = 5; randomness = 20]

1  1.5970649164775934
2  0.48735917935680756
3  0.03401892036532565
4  0.056855435354235886
5  0.057350465618941984
6  0.045755529712813194
7  0.011949237078340974
8  0.05568817147761364
9  0.004842494924412303
10 0.00363714842094364
11 0.000592576550112202
12 0.0038540666119028116
13 0.0008656536766846487
14 0.004005515458042293
15 0.0012341057025147333


Results of Regression Random Forests on Non-Linear Data [ -5 < x < 5 : x*x]. (Not Noisy)

9. As Function of Forest Size [max_depth = 10; min_elements = 5; randomness = 20]

1  0.06299485444466847
2  0.19761003436706875
3  0.03171712833317149
4  0.7183473379946566
5  0.07485969608234695
6  0.06311272394444987
7  0.03241066411309327
8  0.02568227251175073
9  0.04780148201202111
10 0.0367159533355565
11 0.12914995638738652
12 0.036367531300762326
13 0.026723489647410753
14 0.11094913832188576
15 0.015457625021492168
16 0.0160832860537658
17 0.012367316935714434
18 0.051652514165693796
19 0.017521143440651418
20 0.028731269025362483
21 0.015756438992676668
22 0.027990913299780394
23 0.03184875300651329
24 0.035256103804531085
25 0.0074803960259365145
26 0.01280778749783345
27 0.01501064988766935
28 0.0295144327506566
29 0.053027198623329955
30 0.047973371903056915

10. As Function of max_depth [forest_size = 10; min_elements = 5; randomness = 20]

1  23.822990055107432
2  15.333190544607609
3  5.9031711972070635
4  0.36626431195636716
5  0.09758170073138002
6  0.13029048067307347
7  0.40010564796536857
8  0.12035694248931447
9  0.0607850065721469
10 0.04031915262393104
11 0.11298194256550573
12 0.016420044524863734
13 0.02985348021962969
14 0.014566327031516871
15 0.006222659682906706

11. Performance of Locally Weighted Linear Regression (after choosing a suitable value of Hyper-Parameter)
	a. Linear [-5 < x < 0 : x+5 ; 0 < x < 5 : 5-x] : Variance = 0.0008131416646732124 [tau = 0.1]
	b. Non-Linear [ -5 < x < 5 : x*x] : Variance = 0.00633255395418309 [tau = 0.1]

Results of Density Estimation Forests: (Plot the csv files in data_predicted folder)
